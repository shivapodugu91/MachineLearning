finalAccuracy <<- 0
finalPrecision <<- 0
path <<-"~/Desktop/ML/Assignment/Assignment5/iris_raw_dataset.xls"
preprocess <- function()
{
  library(readxl)
  iris_tree<- read_excel(path)
  iris_raw_dataset <- iris_tree
  iris_raw_dataset[iris_raw_dataset$class == "Iris-setosa",]$class = '-1'
  iris_raw_dataset[iris_raw_dataset$class == "Iris-versicolor",]$class =  '0'
  iris_raw_dataset[iris_raw_dataset$class == "Iris-virginica",]$class ='1'
  iris_raw_dataset[, c(5)] <- sapply(iris_raw_dataset[, c(5)], as.numeric)
  iris_raw_dataset_scaled <- as.data.frame(scale(iris_raw_dataset))
  #print("pre process method called")
  return (iris_raw_dataset_scaled)
}

NB<-function(trainset,testset)
{
  x = trainset[,-5]
  y = trainset[,5]
  y <-  as.factor(y)
  
  model = train(x,y,'nb')
  x1 =testset[,-5]
  y1 = testset[,5]
  y1 <-  as.factor(y1)
  con_matrix <- table(predict(model$finalModel,x1)$class,y1)
  precision <- sum(diag(con_matrix))/sum(rowSums(con_matrix))
  precision <- mean(precision) 
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
}

adaboostmethod<-function(train_iris_tree,test_iris_tree)
{
  library(maboost)
  boost <- maboost(as.factor(class)~., data = train_iris_tree, iter = 1, nu =1, bag.frac = 0.5, type = "sparse")
  predictClass <- predict(boost, test_iris_tree)
  con_matrix<-table(predictClass,test_iris_tree$class)
  precision <- sum(diag(con_matrix))/sum(rowSums(con_matrix))
  precision <- mean(precision) 
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
}

baggingmethod<-function()
{
  library(ipred)
  library(readxl)
  library(rpart)
  iris_tree<- read_excel(path)
  iris_raw_dataset <- iris_tree
  iris_raw_dataset[iris_raw_dataset$class == "Iris-setosa",]$class = '-1'
  iris_raw_dataset[iris_raw_dataset$class == "Iris-versicolor",]$class =  '0'
  iris_raw_dataset[iris_raw_dataset$class == "Iris-virginica",]$class ='1'
  iris_raw_dataset[, c(5)] <- sapply(iris_raw_dataset[, c(5)], as.numeric)
  iris_raw_dataset_scaled <- as.data.frame(scale(iris_raw_dataset_scaled))
  k = 10
  sum = 0
  avgAccuracy <- 0
  avgPrecision <- 0
  for (i in 1:k)
  {
    smp_size <- floor(0.75 * nrow(iris_raw_dataset_scaled))
    train_index <- sample(seq_len(nrow(iris_raw_dataset_scaled)), size = smp_size)
    train_iris_tree <- iris_raw_dataset_scaled[train_index, ]
    test_iris_tree <- iris_raw_dataset_scaled[-train_index, ]
    
    model <-bagging(formula = class ~ ., data = train_iris_tree, mfinal = 2,  control = rpart.control(maxdepth = 8))
    predictClass <- predict(model, test_iris_tree)
    predictClass <- scale(predictClass)
    predictClass <- ifelse(predictClass <0, -1,predictClass)
    predictClass <- ifelse(predictClass >1, 1,predictClass)
    predictClass <- round(predictClass)
    con_matrix<-table(round(predictClass),round(test_iris_tree$class))
    accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
    precision <- diag(con_matrix) / rowSums(con_matrix)
    precision <- mean(precision)
    avgAccuracy <- avgAccuracy + accuracy
    avgPrecision <- avgPrecision + mean(precision)
  }
  finalPrecision <<- finalPrecision+precision
  finalAccuracy <<- avgAccuracy /10
  finalPrecision <<-  avgPrecision /10
}

DTmethod<-function(train_iris_tree,test_iris_tree)
{
  library(rpart)
  dtree_fit <- train(class ~., data = train_iris_tree, method = "rpart",tuneLength = 10)
  predict_tree<-predict(dtree_fit,test_iris_tree[,-5])
  con_matrix<-table(predict_tree,test_iris_tree$class)
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  precision <- diag(con_matrix) / rowSums(con_matrix)
  precision <- mean(precision) 
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
}

gradientBoostingmethod<-function(train_iris_tree,test_iris_tree)
{
  library(gbm)
  library(adabag)
  model <- gbm(class~. , data = train_iris_tree, distribution="gaussian", n.trees = 100)
  predictClass <- predict(model, test_iris_tree, n.trees = 100)
  predictClass <- scale(predictClass)
  predictClass <- ifelse(predictClass <0, -1,predictClass)
  predictClass <- ifelse(predictClass >1, 1,predictClass)
  predictClass <- round(predictClass)
  con_matrix<-table(round(predictClass),round(test_iris_tree$class))
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  precision <- diag(con_matrix) / rowSums(con_matrix)
  precision <- mean(precision) 
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
}

LRmethod<-function(train_iris_tree,test_iris_tree)
{
  model <- lm(class~., data = train_iris_tree)
  predictClass <- predict(model,test_iris_tree)
  predictClass <- scale(predictClass)
  predictClass <- ifelse(predictClass <0, -1,predictClass)
  predictClass <- ifelse(predictClass >1, 1,predictClass)
  predictClass <- round(predictClass)
  con_matrix<-table(round(predictClass),round(test_iris_tree$class))
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  precision <- diag(con_matrix) / rowSums(con_matrix)
  precision <- mean(precision)
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
}
Neuralnetmethod<-function(trainset,test_iris_tree)
{
  library(dplyr)
  library(neuralnet)
  irr <- dplyr::select(trainset, -class)
  n <- names(irr)
  f <- as.formula(paste("class ~", paste(n[!n %in% "class"], collapse = " + ")))
  nn <- neuralnet(f, hidden = c(5), data=trainset, lifesign = "minimal", linear.output = TRUE, threshold = 0.1, )
  pred_neuralnet <- compute(nn, testset[,-4])
  pred_neuralnet$net.result <- ifelse(pred_neuralnet$net.result >1, 1,pred_neuralnet$net.result)
  pred_neuralnet$net.result <- ifelse(pred_neuralnet$net.result <0, -1,pred_neuralnet$net.result)
  pred_neuralnet$net.result <- round( pred_neuralnet$net.result)
  con_matrix<-table(pred_neuralnet$net.result,round(test_iris_tree$class))
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  precision <- diag(con_matrix) / rowSums(con_matrix)
  precision <- mean(precision)
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
}
perceptronmethod<-function(trainset,test_iris_tree)
{
  library(dplyr)
  library(neuralnet)
  irr <- dplyr::select(trainset, -class)
  n <- names(irr)
  f <- as.formula(paste("class ~", paste(n[!n %in% "class"], collapse = " + ")))
  nn <- neuralnet(f, hidden = c(0), data=trainset, lifesign = "minimal", linear.output = TRUE, threshold = 0.1, )
  pred_neuralnet <- compute(nn, testset[,-4])
  pred_neuralnet$net.result <- ifelse(pred_neuralnet$net.result >1, 1,pred_neuralnet$net.result)
  pred_neuralnet$net.result <- ifelse(pred_neuralnet$net.result <0, -1,pred_neuralnet$net.result)
  pred_neuralnet$net.result <- round( pred_neuralnet$net.result)
  con_matrix<-table(pred_neuralnet$net.result,round(test_iris_tree$class))
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  precision <- diag(con_matrix) / rowSums(con_matrix)
  precision <- mean(precision)
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
}

DeepLearningmethod<-function(trainset,test_iris_tree)
{
  library(dplyr)
  library(neuralnet)
  irr <- dplyr::select(trainset, -class)
  n <- names(irr)
  f <- as.formula(paste("class ~", paste(n[!n %in% "class"], collapse = " + ")))
  nn <- neuralnet(f, hidden = c(3,4), data=trainset, lifesign = "minimal", linear.output = TRUE, threshold = 0.1, )
  pred_neuralnet <- compute(nn, testset[,-4])
  pred_neuralnet$net.result <- ifelse(pred_neuralnet$net.result >1, 1,pred_neuralnet$net.result)
  pred_neuralnet$net.result <- ifelse(pred_neuralnet$net.result <0, -1,pred_neuralnet$net.result)
  pred_neuralnet$net.result <- round( pred_neuralnet$net.result)
  con_matrix<-table(pred_neuralnet$net.result,round(test_iris_tree$class))
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  precision <- diag(con_matrix) / rowSums(con_matrix)
  precision <- mean(precision)
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
}

randomForestmethod<-function(train_iris_tree,test_iris_tree)
{
library(randomForest)
  model <- randomForest(class~., data=train_iris_tree, ntree = 5, importance = TRUE)
  predictClass <- predict(model, test_iris_tree)
  predictClass <- scale(predictClass)
  predictClass <- ifelse(predictClass <0, -1,predictClass)
  predictClass <- ifelse(predictClass >1, 1,predictClass)
  predictClass <- round(predictClass)
  con_matrix<-table(round(predictClass),round(test_iris_tree$class))
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  precision <- diag(con_matrix) / rowSums(con_matrix)
  precision <- mean(precision)
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
}

SVMmethod<-function()
{
  library(e1071)
  library(readxl)
  iris_raw<- read_excel(path)
  iris_raw[iris_raw$class == "Iris-setosa",]$class = '-1'
  iris_raw[iris_raw$class == "Iris-versicolor",]$class =  '0'
  iris_raw[iris_raw$class == "Iris-virginica",]$class ='1'
  iris_raw[, c(5)] <- sapply(iris_raw[, c(5)], as.numeric)
  iris_raw$sepal_length=scale(iris_raw$sepal_length)
  iris_raw$sepal_width=scale(iris_raw$sepal_width)
  iris_raw$petal_width=scale(iris_raw$petal_width)
  iris_raw$petal_length=scale(iris_raw$petal_length)
  index <- sample(nrow(iris_raw),0.75*nrow(iris_raw))
  train <- iris_raw[index, ]
  test <- iris_raw[-index, ]
  svm1<-svm(class~ ., data=train,type = "C-classification")
  pred <- predict(svm1,test[,-5])
  con_matrix<-table(pred,test$class)
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  precision <- diag(con_matrix) / rowSums(con_matrix)
  precision <- mean(precision)
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
}
KNNmethod <-function(train_iris_tree,test_iris_tree)
{
  library(class)
  knn <-  knn(train_iris_tree[,-5], test_iris_tree[,-5], train_iris_tree[,5], k=10)
  con_matrix1<-table(knn ,test_iris_tree[,5])
  accuracy <- (sum(diag(con_matrix)) / sum(con_matrix))*100.0
  precision <- diag(con_matrix) / rowSums(con_matrix)
  precision <- mean(precision)
  finalAccuracy <<- finalAccuracy+accuracy
  finalPrecision <<- finalPrecision+precision
  
}
library(caret)
library(MASS)

mainFunction<-function(k)
{
  iris_raw_dataset_scaled<-preprocess()
  set.seed(30)
  ScaledData <- iris_raw_dataset_scaled
   #We have applied 10 fold cross validation inside the bagging method.
  baggingmethod()
  for (i in 1:k)
  {
      index <- sample(nrow(ScaledData),0.75*nrow(ScaledData))
     trainset <- ScaledData[index,]
     testset <- ScaledData[-index,]
      NB(trainset,testset)
     adaboostmethod(trainset,testset)
       DTmethod(trainset,testset)
      gradientBoostingmethod(trainset,testset)
     LRmethod(trainset,testset)
     Neuralnetmethod(trainset,testset)
    perceptronmethod(trainset,testset)
     DeepLearningmethod(trainset,testset)
     randomForestmethod(trainset,testset)
    SVMmethod()
     KNNmethod(trainset,testset)
   finalAccuracy <<-finalAccuracy/12
   finalPrecision <<- finalPrecision/12
  }
}

m<-mainFunction(10)
print("Please find below overall average accuracya nd precision:")
finalAccuracy
finalPrecision



